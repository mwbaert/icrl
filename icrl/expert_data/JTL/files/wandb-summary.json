{"eval/mean_reward": 35.0, "eval/mean_ep_length": 6.0, "eval/best_mean_reward": 35.0, "rollout/adjusted_reward": 5.789891242980957, "eval/true_cost": 0.005859375, "time/iterations": 40, "time/fps": 454, "time/time_elapsed": 180, "time/total_timesteps": 81920, "infos/cost": 0.0020101194107463144, "rollout/ep_rew_mean": 35.0, "rollout/ep_len_mean": 6.0, "_step": 81920, "_runtime": 193, "_timestamp": 1653402953, "train/learning_rate": 0.0003, "train/entropy_loss": -0.019968905340647325, "train/policy_gradient_loss": -0.0012145822077364143, "train/reward_value_loss": 4.569256873878658e-05, "train/cost_value_loss": 0.001289970814730168, "train/approx_kl": 0.011297770775854588, "train/clip_fraction": 0.01044921875, "train/loss": 0.000925107509829104, "train/mean_reward_advantages": 0.007685348857194185, "train/mean_cost_advantages": -0.014336341060698032, "train/reward_explained_variance": 0.9936394817195833, "train/cost_explained_variance": -1.5834720134735107, "train/nu": 4.369991779327393, "train/nu_loss": -0.10092836618423462, "train/average_cost": 0.0234375, "train/total_cost": 48.0, "train/early_stop_epoch": 10, "train/n_updates": 390, "train/clip_range": 0.2}