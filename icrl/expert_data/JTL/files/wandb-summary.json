{"eval/mean_reward": 9994.35, "eval/mean_ep_length": 13.2, "eval/best_mean_reward": 9994.5, "rollout/adjusted_reward": 732.941650390625, "eval/true_cost": 0.0, "time/iterations": 196, "time/fps": 717, "time/time_elapsed": 2798, "time/total_timesteps": 2007040, "infos/cost": 0.0, "rollout/ep_rew_mean": 9994.34666667, "rollout/ep_len_mean": 13.65, "_step": 2007040, "_runtime": 2811, "_timestamp": 1653490363, "train/learning_rate": 0.0005, "train/entropy_loss": -0.11940812355605886, "train/policy_gradient_loss": -0.0015444335779803073, "train/reward_value_loss": 3.5141238865321614e-05, "train/cost_value_loss": 4.6089147459627e-08, "train/approx_kl": 0.024693774059414864, "train/clip_fraction": 0.0528564453125, "train/loss": -0.002437496092170477, "train/mean_reward_advantages": 0.02230946719646454, "train/mean_cost_advantages": -3.788488174905069e-05, "train/reward_explained_variance": 0.9959500343538821, "train/cost_explained_variance": -0.018503665924072266, "train/nu": 3.1101934909820557, "train/nu_loss": -0.0, "train/average_cost": 0.0, "train/total_cost": 0.0, "train/early_stop_epoch": 3, "train/n_updates": 1950, "train/clip_range": 0.2}