{"eval/mean_reward": 9994.5, "eval/mean_ep_length": 12.0, "eval/best_mean_reward": 9994.5, "rollout/adjusted_reward": 829.7427978515625, "eval/true_cost": 0.0, "time/iterations": 98, "time/fps": 639, "time/time_elapsed": 313, "time/total_timesteps": 200704, "infos/cost": 0.0, "rollout/ep_rew_mean": 9994.5, "rollout/ep_len_mean": 12.0, "_step": 200704, "_runtime": 328, "_timestamp": 1654768470, "train/learning_rate": 0.0003, "train/entropy_loss": -0.12842989219352602, "train/policy_gradient_loss": -0.0006283996421324225, "train/reward_value_loss": 3.0362434681174832e-05, "train/cost_value_loss": 7.428472115281193e-08, "train/approx_kl": 0.0019615832716226578, "train/clip_fraction": 0.04853515625, "train/loss": 0.0002839399967342615, "train/mean_reward_advantages": -0.0020878210198134184, "train/mean_cost_advantages": -0.0004739552387036383, "train/reward_explained_variance": 0.9985225634882227, "train/cost_explained_variance": 0.09614729881286621, "train/nu": 2.172821283340454, "train/nu_loss": -0.0, "train/average_cost": 0.0, "train/total_cost": 0.0, "train/early_stop_epoch": 10, "train/n_updates": 970, "train/clip_range": 0.2}